{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7ef5998a6e6441ca1515b582fcbc02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8490ecf983fa498683e827e78dc4e9b1",
              "IPY_MODEL_e9ab03c2d5af46209406529f39ef2976",
              "IPY_MODEL_07076fdfd4644d449cb9c7540e371d97"
            ],
            "layout": "IPY_MODEL_56e73595f681497491a60607b6edc0d5"
          }
        },
        "8490ecf983fa498683e827e78dc4e9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_055c398e2a584d49bb30a8b6e74268ce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5908b443b86e45ba948a13218bf1114d",
            "value": "100%"
          }
        },
        "e9ab03c2d5af46209406529f39ef2976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d79c4fa84514401a2ef37aab03f0f5d",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c287b2d2f5d4deaa12a73f338a6e689",
            "value": 111898327
          }
        },
        "07076fdfd4644d449cb9c7540e371d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53aafbbd5b044ff4a4cb11b1f62dd0e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_03fc99bfdae54563bd6a94dbb7089bd6",
            "value": "‚Äá107M/107M‚Äá[00:01&lt;00:00,‚Äá118MB/s]"
          }
        },
        "56e73595f681497491a60607b6edc0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055c398e2a584d49bb30a8b6e74268ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5908b443b86e45ba948a13218bf1114d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d79c4fa84514401a2ef37aab03f0f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c287b2d2f5d4deaa12a73f338a6e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53aafbbd5b044ff4a4cb11b1f62dd0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03fc99bfdae54563bd6a94dbb7089bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Make sure GPU is on: Runtime > Change runtime type > T4 or L4 GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Minimal, stable deps (no albumentations)\n",
        "!pip -q install facenet-pytorch==2.5.3 torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install opencv-python pandas scikit-learn tqdm matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2aouy6e3q4q",
        "outputId": "d73d7362-f762-4fa2-a6ba-eb0999edcbf7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 15 19:23:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: set these two to match your Drive\n",
        "DATA_ROOT = \"/content/drive/MyDrive/data\"   # folder that has the 105 subfolders\n",
        "CSV_PATH  = \"/content/drive/MyDrive/data/dataset.xlsx\"\n",
        "\n",
        "# Artifacts (saved outputs)\n",
        "ARTIFACTS_DIR = \"/content/drive/MyDrive/aiweek_artifacts\"\n",
        "import os; os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwaCJSz04F4I",
        "outputId": "7695cccb-219d-4d8c-eacd-6c1784934f6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.makedirs(ARTIFACTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "by3mZYHF4VqJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"DATA_ROOT exists?\", os.path.exists(DATA_ROOT))\n",
        "print(\"CSV_PATH exists?\", os.path.exists(CSV_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8qr1sM34cW8",
        "outputId": "399a9f8d-e0c3-4511-c764-a8137b03bba2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT exists? True\n",
            "CSV_PATH exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openpyxl"
      ],
      "metadata": {
        "id": "RNotMQ-g4iQs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "assert os.path.exists(CSV_PATH), f\"Excel not found at {CSV_PATH}\"\n",
        "\n",
        "df = pd.read_excel(CSV_PATH)  # expects columns: ID, Name, Status, Age\n",
        "# Normalize column names just in case\n",
        "df.columns = [c.strip().lower() for c in df.columns]\n",
        "\n",
        "required = {\"id\",\"name\",\"status\"}\n",
        "missing = required - set(df.columns)\n",
        "assert not missing, f\"Missing columns in Excel: {missing}. Found: {df.columns}\"\n",
        "\n",
        "# Build maps\n",
        "id2name   = {str(r[\"id\"]).strip(): str(r[\"name\"]).strip() for _, r in df.iterrows()}\n",
        "name2id   = {str(r[\"name\"]).strip(): str(r[\"id\"]).strip() for _, r in df.iterrows()}\n",
        "id2status = {str(r[\"id\"]).strip(): str(r[\"status\"]).strip().lower() for _, r in df.iterrows()}\n",
        "id2age    = {str(r[\"id\"]).strip(): int(r[\"age\"]) if \"age\" in df.columns and pd.notna(r[\"age\"]) else None\n",
        "             for _, r in df.iterrows()}\n",
        "\n",
        "print(f\"Rows in Excel: {len(df)}\")\n",
        "print(\"Sample:\", list(id2name.items())[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8Wk9iI4mhQ",
        "outputId": "6bf85ffe-56f6-4d04-fcf3-5704334109ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows in Excel: 105\n",
            "Sample: [('bf723908-8899-11f0-bbe4-0242ac1c000c', 'Adriana Lima'), ('bf723a48-8899-11f0-bbe4-0242ac1c000c', 'Alex Lawther'), ('bf723aca-8899-11f0-bbe4-0242ac1c000c', 'Alexandra Daddario')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, glob\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- helpers ----------\n",
        "PREFIXES = (\"pins_\", \"imgs_\", \"images_\", \"photos_\", \"pics_\", \"train_\", \"val_\", \"set_\", \"folder_\")\n",
        "\n",
        "def norm_name(s: str) -> str:\n",
        "    s = str(s)\n",
        "    # strip common prefixes\n",
        "    for pref in PREFIXES:\n",
        "        if s.lower().startswith(pref):\n",
        "            s = s[len(pref):]\n",
        "            break\n",
        "    # replace separators with spaces\n",
        "    s = s.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "    # collapse spaces, lowercase\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
        "    return s\n",
        "\n",
        "# Excel maps (MUST exist from your earlier cell B)\n",
        "# id2name, name2id, id2status, id2age\n",
        "assert \"id2name\" in globals() and \"name2id\" in globals() and \"id2status\" in globals()\n",
        "\n",
        "# Build normalized name map from Excel\n",
        "name2id_norm = {norm_name(name): uid for name, uid in name2id.items()}\n",
        "\n",
        "# ---------- scan folders ----------\n",
        "assert os.path.exists(DATA_ROOT), f\"DATA_ROOT not found: {DATA_ROOT}\"\n",
        "image_exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\")\n",
        "\n",
        "folder_map = {}\n",
        "canonical_to_images = defaultdict(list)\n",
        "canonical_meta = {}\n",
        "\n",
        "matched_by_id = matched_by_name = 0\n",
        "unmatched = []\n",
        "\n",
        "for folder in sorted(os.listdir(DATA_ROOT)):\n",
        "    fpath = os.path.join(DATA_ROOT, folder)\n",
        "    if not os.path.isdir(fpath):\n",
        "        continue\n",
        "\n",
        "    files = []\n",
        "    for ext in image_exts:\n",
        "        files += glob.glob(os.path.join(fpath, ext))\n",
        "    if not files:\n",
        "        continue\n",
        "\n",
        "    canonical_id = None\n",
        "    name = folder\n",
        "    status, age = \"unknown\", None\n",
        "\n",
        "    # try: exact folder == Excel ID\n",
        "    if folder in id2name:\n",
        "        canonical_id = folder\n",
        "        name   = id2name[canonical_id]\n",
        "        status = id2status.get(canonical_id, \"unknown\")\n",
        "        age    = id2age.get(canonical_id, None)\n",
        "        matched_by_id += 1\n",
        "    else:\n",
        "        # try: normalized folder name matches Excel name\n",
        "        n = norm_name(folder)\n",
        "        if n in name2id_norm:\n",
        "            canonical_id = name2id_norm[n]\n",
        "            name   = id2name[canonical_id]\n",
        "            status = id2status.get(canonical_id, \"unknown\")\n",
        "            age    = id2age.get(canonical_id, None)\n",
        "            matched_by_name += 1\n",
        "        else:\n",
        "            canonical_id = folder   # fallback\n",
        "            unmatched.append(folder)\n",
        "\n",
        "    folder_map[folder] = canonical_id\n",
        "    canonical_to_images[canonical_id].extend(sorted(files))\n",
        "    canonical_meta[canonical_id] = {\n",
        "        \"name\": name,\n",
        "        \"status\": str(status).strip().lower(),\n",
        "        \"age\": age\n",
        "    }\n"
      ],
      "metadata": {
        "id": "6nSkbinq4uwk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_APPROVED_ONLY = True  # flip to False if you just want to move on\n",
        "\n",
        "selected_ids = []\n",
        "for cid, meta in canonical_meta.items():\n",
        "    st = meta.get(\"status\", \"unknown\")\n",
        "    st = st.strip().lower() if isinstance(st, str) else \"unknown\"\n",
        "    is_ok = (not USE_APPROVED_ONLY) or (\"approved\" in st)\n",
        "    if is_ok and len(canonical_to_images[cid]) > 0:\n",
        "        selected_ids.append(cid)\n",
        "\n",
        "print(f\"‚úÖ Selected identities: {len(selected_ids)} (USE_APPROVED_ONLY={USE_APPROVED_ONLY})\")\n",
        "if USE_APPROVED_ONLY and len(selected_ids) == 0:\n",
        "    print(\"‚ö†Ô∏è Still no approved users. Try USE_APPROVED_ONLY=False to proceed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQcTDWr-4wBw",
        "outputId": "25bc31db-9954-413c-fb7d-9f46fff314bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Selected identities: 48 (USE_APPROVED_ONLY=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSXK-2A2406X",
        "outputId": "50f9ff5c-6453-4bf7-894e-637a04bf0e28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.7/3.2 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "train_index, val_index = [], []\n",
        "\n",
        "for cid in selected_ids:\n",
        "    imgs = list(canonical_to_images[cid])\n",
        "    random.shuffle(imgs)\n",
        "    if len(imgs) == 1:\n",
        "        train_index.append((cid, imgs[0]))\n",
        "        continue\n",
        "    cut = max(1, int(0.8 * len(imgs)))\n",
        "    train_index += [(cid, p) for p in imgs[:cut]]\n",
        "    val_index   += [(cid, p) for p in imgs[cut:]]\n",
        "\n",
        "print(\"‚úÖ Train images:\", len(train_index))\n",
        "print(\"‚úÖ Val images:\",   len(val_index))\n",
        "print(\"Example train sample:\", train_index[0] if train_index else \"‚Äî\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbQwQYiD46r2",
        "outputId": "2e0d9a49-2e85-43b4-b423-d95f68611dee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train images: 5700\n",
            "‚úÖ Val images: 1445\n",
            "Example train sample: ('bf723aca-8899-11f0-bbe4-0242ac1c000c', '/content/drive/MyDrive/data/pins_Alexandra Daddario/Alexandra Daddario233_345.jpg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from PIL import Image\n",
        "\n",
        "# Pick device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Face detector (MTCNN)\n",
        "mtcnn = MTCNN(image_size=160, margin=14, post_process=True, keep_all=False, device=device)\n",
        "\n",
        "\n",
        "# Face embedding model (FaceNet, pretrained on VGGFace2)\n",
        "embedder = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "# Helper function: image -> 512-D embedding\n",
        "def image_to_embedding(path):\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not open image {path}: {e}\")\n",
        "        return None, False\n",
        "\n",
        "    # Detect and crop face\n",
        "    face = mtcnn(img)\n",
        "    if face is None:\n",
        "        return None, False\n",
        "\n",
        "    # Generate embedding\n",
        "    with torch.no_grad():\n",
        "        emb = embedder(face.unsqueeze(0).to(device))\n",
        "        emb = torch.nn.functional.normalize(emb, dim=1)  # normalize for cosine similarity\n",
        "\n",
        "    return emb.squeeze(0).cpu(), True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b7ef5998a6e6441ca1515b582fcbc02f",
            "8490ecf983fa498683e827e78dc4e9b1",
            "e9ab03c2d5af46209406529f39ef2976",
            "07076fdfd4644d449cb9c7540e371d97",
            "56e73595f681497491a60607b6edc0d5",
            "055c398e2a584d49bb30a8b6e74268ce",
            "5908b443b86e45ba948a13218bf1114d",
            "2d79c4fa84514401a2ef37aab03f0f5d",
            "4c287b2d2f5d4deaa12a73f338a6e689",
            "53aafbbd5b044ff4a4cb11b1f62dd0e9",
            "03fc99bfdae54563bd6a94dbb7089bd6"
          ]
        },
        "id": "ickTzIWQ4_YN",
        "outputId": "d3930c79-48ea-4280-8103-3c803fcedbb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7ef5998a6e6441ca1515b582fcbc02f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def batch_embed(pairs):\n",
        "    \"\"\"Compute embeddings for (identity, image_path) pairs.\"\"\"\n",
        "    out, misses = [], 0\n",
        "    for cid, path in tqdm(pairs):\n",
        "        emb, ok = image_to_embedding(path)\n",
        "        if ok:\n",
        "            out.append((cid, path, emb))\n",
        "        else:\n",
        "            misses += 1\n",
        "    return out, misses\n",
        "\n",
        "# Run for train and val sets\n",
        "train_embs, train_miss = batch_embed(train_index)\n",
        "val_embs,   val_miss   = batch_embed(val_index)\n",
        "\n",
        "print(f\"‚úÖ Got embeddings:\")\n",
        "print(f\"   ‚Ä¢ Train = {len(train_embs)} (missed {train_miss})\")\n",
        "print(f\"   ‚Ä¢ Val   = {len(val_embs)} (missed {val_miss})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKHSlPPm5KCD",
        "outputId": "b932132e-6464-4976-cdd4-3ea3240935e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5700/5700 [35:17<00:00,  2.69it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1445/1445 [08:57<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Got embeddings:\n",
            "   ‚Ä¢ Train = 5680 (missed 20)\n",
            "   ‚Ä¢ Val   = 1438 (missed 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Group embeddings per identity\n",
        "proto = defaultdict(list)\n",
        "for cid, _, emb in train_embs:\n",
        "    proto[cid].append(emb)\n",
        "\n",
        "# Mean + L2-normalize ‚Üí the identity prototype\n",
        "for cid in list(proto.keys()):\n",
        "    m = torch.stack(proto[cid], dim=0).mean(0)\n",
        "    proto[cid] = torch.nn.functional.normalize(m.unsqueeze(0), dim=1).squeeze(0)\n",
        "\n",
        "print(f\"‚úÖ Built prototypes for {len(proto)} identities\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Viu6j6Up5Ooi",
        "outputId": "52cec546-c696-4cf1-f951-d365fb99b1fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Built prototypes for 48 identities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json, os\n",
        "\n",
        "def cosine(a, b):\n",
        "    return torch.nn.functional.cosine_similarity(\n",
        "        a.unsqueeze(0), b.unsqueeze(0)\n",
        "    ).item()\n",
        "\n",
        "# Collect positive and negative cosine scores\n",
        "pos, neg = [], []\n",
        "\n",
        "# Positive: same identity\n",
        "for cid, _, emb in val_embs:\n",
        "    if cid in proto:\n",
        "        pos.append(cosine(emb, proto[cid]))\n",
        "\n",
        "# Negative: claim wrong identity\n",
        "candidate_ids = list(proto.keys())\n",
        "for cid, _, emb in val_embs:\n",
        "    others = [x for x in candidate_ids if x != cid]\n",
        "    if not others:\n",
        "        continue\n",
        "    claim = random.choice(others)\n",
        "    neg.append(cosine(emb, proto[claim]))\n",
        "\n",
        "# Sweep thresholds\n",
        "scores = sorted(set([round(s, 4) for s in (pos + neg)]))\n",
        "best_t, best_acc = 0.0, 0.0\n",
        "for t in scores:\n",
        "    tp = sum(s >= t for s in pos)\n",
        "    fn = sum(s <  t for s in pos)\n",
        "    tn = sum(s <  t for s in neg)\n",
        "    fp = sum(s >= t for s in neg)\n",
        "    acc = (tp + tn) / max(1, (tp + tn + fp + fn))\n",
        "    if acc > best_acc:\n",
        "        best_acc, best_t = acc, t\n",
        "\n",
        "print(f\"‚úÖ Threshold selected: {best_t:.4f}\")\n",
        "print(f\"   Validation Accuracy: {best_acc*100:.2f}%\")\n",
        "print(f\"   Npos={len(pos)} | Nneg={len(neg)}\")\n",
        "\n",
        "# Save artifacts for later inference\n",
        "torch.save({k: v for k, v in proto.items()}, os.path.join(ARTIFACTS_DIR, \"prototypes.pt\"))\n",
        "with open(os.path.join(ARTIFACTS_DIR, \"id2name.json\"), \"w\") as f:\n",
        "    json.dump({k: canonical_meta[k][\"name\"] for k in proto.keys()}, f)\n",
        "with open(os.path.join(ARTIFACTS_DIR, \"id2status.json\"), \"w\") as f:\n",
        "    json.dump({k: canonical_meta[k][\"status\"] for k in proto.keys()}, f)\n",
        "with open(os.path.join(ARTIFACTS_DIR, \"threshold.json\"), \"w\") as f:\n",
        "    json.dump({\"threshold\": float(best_t)}, f)\n",
        "\n",
        "print(\"‚úÖ Artifacts saved to:\", ARTIFACTS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXAB0iDEOtb",
        "outputId": "a9a7f079-5a89-47e5-cadc-def87c13b433"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Threshold selected: 0.4660\n",
            "   Validation Accuracy: 99.48%\n",
            "   Npos=1438 | Nneg=1438\n",
            "‚úÖ Artifacts saved to: /content/drive/MyDrive/aiweek_artifacts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, torch\n",
        "\n",
        "# Reload artifacts (safe even in a fresh session)\n",
        "prototypes = torch.load(os.path.join(ARTIFACTS_DIR, \"prototypes.pt\"), map_location='cpu')\n",
        "threshold  = json.load(open(os.path.join(ARTIFACTS_DIR, \"threshold.json\")))[\"threshold\"]\n",
        "id2name_art   = json.load(open(os.path.join(ARTIFACTS_DIR, \"id2name.json\")))\n",
        "id2status_art = json.load(open(os.path.join(ARTIFACTS_DIR, \"id2status.json\")))\n",
        "\n",
        "def cosine(a, b):\n",
        "    return torch.nn.functional.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0)).item()\n",
        "\n",
        "def verify_claim(claimed_id: str, image_path: str):\n",
        "    \"\"\"Verify a claimed ID against an image path.\"\"\"\n",
        "    t0 = time.time()\n",
        "    emb, ok = image_to_embedding(image_path)\n",
        "    if not ok:\n",
        "        return {\"status\":\"face_not_found\",\"claimed_id\":claimed_id}\n",
        "\n",
        "    if claimed_id not in prototypes:\n",
        "        return {\"status\":\"unknown_user\",\"claimed_id\":claimed_id}\n",
        "\n",
        "    score = cosine(emb, prototypes[claimed_id])\n",
        "    decision = \"ACCESS_GRANTED\" if score >= threshold else \"ACCESS_DENIED\"\n",
        "    return {\n",
        "        \"status\": decision.lower(),\n",
        "        \"score\": float(score),\n",
        "        \"threshold\": float(threshold),\n",
        "        \"claimed_id\": claimed_id,\n",
        "        \"claimed_name\": id2name_art.get(claimed_id, claimed_id),\n",
        "        \"claimed_status\": id2status_art.get(claimed_id, \"unknown\"),\n",
        "        \"time_ms\": int((time.time()-t0)*1000),\n",
        "        \"model\": \"facenet_vggface2\",\n",
        "    }\n",
        "\n",
        "# --- Smoke test ---\n",
        "if val_embs:\n",
        "    cid, path, _ = val_embs[0]\n",
        "    result = verify_claim(cid, path)\n",
        "    print(\"‚úÖ Smoke test result:\\n\", result)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No validation images available to test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r47tHbFzEcQ-",
        "outputId": "c895cbeb-ad67-423d-ac59-4d8d3695c03b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Smoke test result:\n",
            " {'status': 'access_granted', 'score': 0.7191963195800781, 'threshold': 0.466, 'claimed_id': 'bf723aca-8899-11f0-bbe4-0242ac1c000c', 'claimed_name': 'Alexandra Daddario', 'claimed_status': 'approved', 'time_ms': 47, 'model': 'facenet_vggface2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# pick a real val image\n",
        "cid_true, path, _ = val_embs[0]\n",
        "\n",
        "# claim a different ID on purpose\n",
        "other_ids = [k for k in prototypes.keys() if k != cid_true]\n",
        "claimed_wrong = random.choice(other_ids)\n",
        "\n",
        "print(\"True ID:\", cid_true, \"| Wrong claim:\", claimed_wrong)\n",
        "print(\"NEG example:\", verify_claim(claimed_wrong, path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LNZ-h07Eg1M",
        "outputId": "6d81e9e8-5d5d-4b74-f133-58cb8505d6fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True ID: bf723aca-8899-11f0-bbe4-0242ac1c000c | Wrong claim: bf724916-8899-11f0-bbe4-0242ac1c000c\n",
            "NEG example: {'status': 'access_denied', 'score': -0.23200075328350067, 'threshold': 0.466, 'claimed_id': 'bf724916-8899-11f0-bbe4-0242ac1c000c', 'claimed_name': 'Eliza Taylor', 'claimed_status': 'approved', 'time_ms': 220, 'model': 'facenet_vggface2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, torch\n",
        "\n",
        "tp = tn = fp = fn = 0\n",
        "\n",
        "# positives: correct claims\n",
        "for cid, _, emb in val_embs:\n",
        "    if cid not in prototypes:\n",
        "        continue\n",
        "    s = torch.nn.functional.cosine_similarity(\n",
        "        emb.unsqueeze(0), prototypes[cid].unsqueeze(0)\n",
        "    ).item()\n",
        "    pred = (s >= threshold)\n",
        "    tp += int(pred)\n",
        "    fn += int(not pred)\n",
        "\n",
        "# negatives: wrong claims (one impostor per sample)\n",
        "proto_ids = list(prototypes.keys())\n",
        "for cid, _, emb in val_embs:\n",
        "    impostors = [x for x in proto_ids if x != cid]\n",
        "    if not impostors:\n",
        "        continue\n",
        "    wrong = random.choice(impostors)\n",
        "    s = torch.nn.functional.cosine_similarity(\n",
        "        emb.unsqueeze(0), prototypes[wrong].unsqueeze(0)\n",
        "    ).item()\n",
        "    pred = (s >= threshold)  # predicting granted here counts as false accept\n",
        "    fp += int(pred)\n",
        "    tn += int(not pred)\n",
        "\n",
        "acc = (tp + tn) / max(1, (tp+tn+fp+fn))\n",
        "far = fp / max(1, (fp+tn))  # impostor acceptance rate\n",
        "frr = fn / max(1, (fn+tp))  # genuine rejection rate\n",
        "\n",
        "print(f\"Accuracy: {acc*100:.2f}% | FAR: {far*100:.2f}% | FRR: {frr*100:.2f}%\")\n",
        "print(f\"Confusion -> TP:{tp} TN:{tn} FP:{fp} FN:{fn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqciLkeZExuJ",
        "outputId": "c9fdad6d-d94f-47a5-9bb1-cad72bd99f6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.17% | FAR: 1.04% | FRR: 0.63%\n",
            "Confusion -> TP:1429 TN:1423 FP:15 FN:9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch, time\n",
        "\n",
        "# reuse what's already in memory:\n",
        "# - prototypes, threshold, id2name_art, image_to_embedding()\n",
        "\n",
        "proto_ids   = list(prototypes.keys())\n",
        "id_choices  = [(id2name_art.get(cid, cid), cid) for cid in proto_ids]  # (label, value)\n",
        "\n",
        "def cosine(a,b):\n",
        "    return torch.nn.functional.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0)).item()\n",
        "\n",
        "def verify_ui(claimed_id, image):\n",
        "    if image is None:\n",
        "        return {\"status\":\"no_file\"}\n",
        "    # gradio gives PIL.Image\n",
        "    face = mtcnn(image.convert(\"RGB\"))\n",
        "    if face is None:\n",
        "        return {\"status\":\"face_not_found\"}\n",
        "    with torch.no_grad():\n",
        "        emb = embedder(face.unsqueeze(0).to(device))\n",
        "        emb = torch.nn.functional.normalize(emb, dim=1).squeeze(0).cpu()\n",
        "    if claimed_id not in prototypes:\n",
        "        return {\"status\":\"unknown_user\"}\n",
        "    score = cosine(emb, prototypes[claimed_id])\n",
        "    decision = \"ACCESS_GRANTED\" if score >= threshold else \"ACCESS_DENIED\"\n",
        "    return {\n",
        "        \"status\": decision.lower(),\n",
        "        \"score\": float(score),\n",
        "        \"threshold\": float(threshold),\n",
        "        \"claimed_id\": claimed_id,\n",
        "        \"claimed_name\": id2name_art.get(claimed_id, claimed_id),\n",
        "    }\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üîê Face Verification Demo\\nUpload a face image and select the claimed user.\")\n",
        "    with gr.Row():\n",
        "        claimed = gr.Dropdown(choices=[v for _, v in id_choices], label=\"Claimed ID\")\n",
        "        img     = gr.Image(type=\"pil\", label=\"Face image\")\n",
        "    btn = gr.Button(\"Verify\")\n",
        "    out = gr.JSON(label=\"Result\")\n",
        "\n",
        "    btn.click(fn=verify_ui, inputs=[claimed, img], outputs=out)\n",
        "\n",
        "demo.launch(share=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "BRgI_G7VE9Bl",
        "outputId": "dbe19902-7229-43c3-f9cf-e33e69cc636d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}